# ğŸ¥ Medical Telegram Warehouse

**Medical Telegram Warehouse** is a robust data engineering pipeline designed to collect, process, and analyze medical data sourced from Telegram channels. The project integrates scraping, data warehousing, and object detection to build a comprehensive medical data repository.

---

## ğŸš€ Key Features

- **Telegram Scraping**: Automated scraping of messages and images from specific medical Telegram channels (`lobelia4cosmetics`, `chemed`, `tikvahpharma`) using `Telethon`.
- **Data Ingestion**: Seamless loading of raw scraped data into a **PostgreSQL** database.
- **Data Transformation**: Implementation of **dbt (data build tool)** for cleaning, testing, and transforming raw data into a Star Schema (Facts and Dimensions).
- **Object Detection**: (Planned/In-progress) Integration of **YOLO** (`ultralytics`) for detecting objects in medical images.
- **API**: (In-progress) exposing data via **FastAPI**.
- **Orchestration**: Managed workflows using **Dagster**.

---

## ğŸ“‚ Project Structure

```bash
medical-telegram-warehouse/
â”œâ”€â”€ .github/workflows/   # CI/CD workflows
â”œâ”€â”€ api/                 # FastAPI application
â”œâ”€â”€ data/derived/        # Processed data
â”œâ”€â”€ data/raw/            # Raw scraped data (images/json)
â”œâ”€â”€ medical_warehouse/   # dbt project folder
â”‚   â”œâ”€â”€ models/          # dbt models (staging, marts)
â”‚   â”œâ”€â”€ analyses/        # dbt analyses
â”‚   â””â”€â”€ tests/           # dbt tests
â”œâ”€â”€ notebooks/           # Jupyter notebooks for EDA and testing
â”œâ”€â”€ scripts/             # Utility scripts
â”œâ”€â”€ src/                 # Source code for scraper and loader
â”‚   â”œâ”€â”€ scraper.py       # Telegram scraper script
â”‚   â””â”€â”€ loader.py        # Database loader script
â”œâ”€â”€ tests/               # Unit and integration tests
â”œâ”€â”€ .env                 # Environment variables
â”œâ”€â”€ docker-compose.yml   # Docker services configuration
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ› ï¸ Tech Stack

- **Language**: Python
- **Database**: PostgreSQL
- **Transformation**: dbt (Data Build Tool)
- **Scraping**: Telethon
- **Web Framework**: FastAPI
- **Computer Vision**: YOLOv8 (Ultralytics), OpenCV
- **Orchestration**: Dagster
- **Containerization**: Docker

---

## âš¡ Getting Started

### Prerequisites

- Python 3.8+
- PostgreSQL
- Telegram API Credentials (`API_ID`, `API_HASH`)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/eyuBirhanu/medical-telegram-warehouse.git
   cd medical-telegram-warehouse
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python -m venv venv
   # Windows
   .\venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Environment Setup:**
   Create a `.env` file in the root directory and add your credentials:
   ```properties
   # Telegram API
   TG_API_ID=your_api_id
   TG_API_HASH=your_api_hash
   
   # Database
   DB_HOST=localhost
   DB_PORT=5432
   DB_USER=postgres
   DB_PASSWORD=your_password
   DB_NAME=medical_warehouse
   
   # Database Connection String for Loader
   DATABASE_URL=postgresql://postgres:your_password@localhost:5432/medical_warehouse
   ```

---

## ğŸ“Š Usage

### 1. Scraping Data
Run the scraper to fetch latest messages and images from configured channels:
```bash
python src/scraper.py
```

### 2. Loading Data
Load the scraped JSON data into the PostgreSQL raw layer:
```bash
python src/loader.py
```

### 3. Running dbt Transformations
Navigate to the dbt project directory and run the models:
```bash
cd medical_warehouse
dbt run
```

To test the models:
```bash
dbt test
```

### 4. Running the API (Coming Soon)
```bash
uvicorn api.main:app --reload
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please fork the repository and submit a pull request for any enhancements or bug fixes.

## ğŸ“„ License

This project is licensed under the MIT License.